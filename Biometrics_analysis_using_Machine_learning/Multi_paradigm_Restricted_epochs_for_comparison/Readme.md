# Task-Based Biometric Identification Analysis

This project contains a series of Python scripts to evaluate and compare different machine learning models for a biometric identification task. The analysis is performed on a per-task basis, using features extracted from physiological signals.

The following models are implemented and compared:
1.  **1D Convolutional Neural Network (CNN)**
2.  **Mahalanobis Distance Classifier**
3.  **Classical Machine Learning Classifiers** (Logistic Regression, Random Forest, SVM)

## File Descriptions

-   `CNN_Task_Perf.py`: Trains and evaluates a 1D-CNN model over multiple runs to produce an aggregated performance report (Accuracy and EER).
-   `Maha_each_task.py`: Implements a Mahalanobis Distance-based classifier, running multiple iterations with random sampling to report averaged task-wise performance.
-   `ML_Classifier_each_task_file_final_average_EER.py`: Trains and evaluates several classical ML models (Logistic Regression, Random Forest, SVM) and aggregates their performance.

## Setup

1.  **Clone the repository:**
    ```bash
    git clone [https://github.com/your-username/your-repo-name.git](https://github.com/your-username/your-repo-name.git)
    cd your-repo-name
    ```

2.  **Create a virtual environment (recommended):**
    ```bash
    python -m venv venv
    source venv/bin/activate  # On Windows, use `venv\Scripts\activate`
    ```

3.  **Install dependencies:**
    ```bash
    pip install -r requirements.txt
    ```

## Data

This project requires two data files, which should be placed in the root directory:

1.  `all_subjects_merged_new_full_epochs.h5`: An HDF5 file containing the features, labels, run numbers, and epoch numbers.
2.  `epoch_mapping.csv`: A CSV file that maps subjects and epochs to their original source task/file.

**[IMPORTANT: Add a note here about where to get the data. For example: "The data can be downloaded from [link-to-data.com]" or "The data can be generated by running the script located in `data_preprocessing/`."]**

## How to Run the Analyses

You can run each analysis script independently from the terminal. The scripts will automatically create output directories (`cnn_final_report`, `mahalanobis_averaged_results`, etc.) with performance reports and plots.

-   **Run the CNN analysis:**
    ```bash
    python CNN_Task_Perf.py
    ```

-   **Run the Mahalanobis Distance analysis:**
    ```bash
    python Maha_each_task.py
    ```

-   **Run the classical ML classifiers analysis:**
    ```bash
    python ML_Classifier_each_task_file_final_average_EER.py
    ```

## Expected Output

Each script will generate a folder containing:
-   A final `.csv` report with the mean/std of accuracy and EER for each task.
-   Plots visualizing the results (e.g., mean accuracy bar chart, confusion matrices).
-   Intermediate artifacts or per-run results where applicable.